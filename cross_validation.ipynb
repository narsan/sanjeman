{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  Note\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9756786051125674, 0.00443660789743655)\n",
      "accuracy :  0.7712765957446809\n",
      "col_0         2   3\n",
      "steps_title        \n",
      "2            74  20\n",
      "3            23  71\n",
      "112    44253\n",
      "28     47259\n",
      "11     46145\n",
      "39     46135\n",
      "31      3665\n",
      "145    46207\n",
      "152     3419\n",
      "174     8831\n",
      "53     46335\n",
      "Name: job_applicant_id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "     job_applicant_id  gender   age  marriage_status  languages  \\\n112             44253     0.0  41.0              NaN          0   \n28              47259     0.0  24.0              NaN          0   \n177              9280     NaN  27.0              NaN          0   \n11              46145     0.0  30.0              NaN          0   \n39              46135     0.0  35.0              NaN          0   \n31               3665     NaN  32.0              NaN          0   \n33              29650     NaN  36.0              NaN          0   \n145             46207     0.0  37.0              NaN          0   \n152              3419     NaN  35.0              NaN          1   \n174              8831     0.0   NaN              NaN          0   \n53              46335     0.0  35.0              NaN          0   \n35              46036     0.0   NaN              NaN          0   \n3               19161     0.0  25.0              NaN          0   \n50              46164     0.0  30.0              NaN          0   \n129             46809     0.0   NaN              NaN          0   \n110             46422     0.0   NaN              NaN          0   \n104              8822     NaN  37.0              NaN          1   \n68               9086     NaN  34.0              NaN          0   \n77              46083     0.0   NaN              NaN          0   \n105              2239     NaN  30.0              NaN          1   \n71              49263     NaN  38.0              NaN          0   \n168              3301     0.0  40.0              NaN          0   \n85              50512     0.0   NaN              NaN          0   \n6                9303     0.0   NaN              NaN          0   \n88              46034     0.0   NaN              NaN          0   \n73              46099     0.0   NaN              NaN          0   \n80              46105     0.0   NaN              NaN          0   \n22              46028     0.0   NaN              NaN          0   \n124             46102     0.0   NaN              NaN          0   \n26               3597     NaN  24.0              NaN          0   \n180             46562     0.0  26.0              NaN          0   \n186              8265     0.0   NaN              NaN          0   \n75              46031     0.0   NaN              NaN          0   \n138             46384     0.0   NaN              NaN          0   \n1                1845     NaN  42.0              NaN          1   \n69              20580     0.0  37.0              NaN          0   \n23              46129     0.0  28.0              NaN          0   \n21              46381     0.0  28.0              NaN          0   \n170             46956     NaN  35.0              NaN          0   \n29              22443     0.0  40.0              NaN          0   \n158             46650     NaN  35.0              NaN          0   \n51              45788     NaN  40.0              NaN          0   \n106             40811     NaN  35.0              NaN          0   \n122              2189     0.0  21.0              NaN          0   \n150              1180     NaN  45.0              NaN          1   \n141              6251     NaN  44.0              NaN          1   \n167              3410     0.0  48.0              NaN          0   \n48              46879     0.0  33.0              NaN          0   \n65              24676     0.0  38.0              NaN          0   \n43              42128     NaN  31.0              NaN          0   \n\n     contract_type  degree  average_gpa  skill  num_prev_company  \\\n112              0     NaN          NaN      1                 1   \n28               0     NaN          NaN      1                 1   \n177              0     NaN          NaN      1                 2   \n11               0     NaN          NaN      1                 1   \n39               0     NaN          NaN      1                 1   \n31               0     NaN          NaN      1                 1   \n33               1     NaN          NaN      1                 1   \n145              0     NaN          NaN      1                 1   \n152              0     NaN          NaN      1                 1   \n174              0     4.0       17.700      1                 1   \n53               0     NaN          NaN      1                 1   \n35               0     4.0       16.000      1                 2   \n3                0     NaN          NaN      1                 1   \n50               0     NaN          NaN      1                 1   \n129              0     4.0       18.000      1                 4   \n110              0     4.0       17.180      1                 3   \n104              1     4.0          NaN      1                 8   \n68               0     NaN          NaN      1                 1   \n77               0     3.0       19.200      1                 1   \n105              1     NaN          NaN      1                 3   \n71               1     NaN          NaN      1                 1   \n168              0     3.0       16.400      1                 1   \n85               0     4.0       17.500      1                 1   \n6                0     3.0       13.000      1                 1   \n88               0     3.0       14.000      1                 1   \n73               0     4.0       18.265      1                 2   \n80               0     4.0       16.500      1                 2   \n22               0     1.0       18.000      1                 1   \n124              0     4.0       14.000      1                 1   \n26               0     NaN          NaN      1                 1   \n180              0     NaN          NaN      1                 1   \n186              1     NaN          NaN      1                 1   \n75               0     4.0       16.325      1                10   \n138              0     3.0       14.800      1                 3   \n1                1     NaN          NaN      1                 1   \n69               1     NaN          NaN      1                 1   \n23               0     NaN          NaN      1                 1   \n21               0     NaN          NaN      1                 1   \n170              0     NaN          NaN      1                 1   \n29               1     NaN          NaN      1                 1   \n158              0     NaN          NaN      1                 1   \n51               1     NaN          NaN      1                 1   \n106              0     4.0       16.720      1                 1   \n122              0     2.0       16.000      1                 1   \n150              1     NaN          NaN      1                 1   \n141              1     3.0          NaN      1                 1   \n167              0     NaN          NaN      1                 1   \n48               0     NaN          NaN      1                 1   \n65               1     NaN          NaN      1                 1   \n43               1     NaN          NaN      1                 1   \n\n     work_interval  steps_title  prediction    Prob_0    Prob_1  \n112              0            2           2  0.997357  0.002643  \n28               0            2           2  0.994886  0.005114  \n177              4            3           2  0.994599  0.005402  \n11               0            2           2  0.993616  0.006384  \n39               0            2           2  0.992919  0.007081  \n31               0            2           2  0.991989  0.008011  \n33               0            3           2  0.991203  0.008797  \n145              0            2           2  0.990516  0.009484  \n152              1            2           2  0.987167  0.012833  \n174              0            2           2  0.986791  0.013209  \n53               0            2           2  0.985937  0.014063  \n35               0            2           2  0.984359  0.015641  \n3                0            2           2  0.983733  0.016267  \n50               0            2           2  0.982425  0.017575  \n129              0            2           2  0.982358  0.017642  \n110              0            2           2  0.981904  0.018096  \n104             14            3           2  0.980961  0.019039  \n68               0            3           2  0.980165  0.019835  \n77               0            2           2  0.979746  0.020254  \n105             20            2           2  0.979535  0.020465  \n71               0            2           2  0.977627  0.022373  \n168              0            2           2  0.976412  0.023588  \n85               0            2           2  0.975682  0.024317  \n6                0            2           2  0.972087  0.027913  \n88               0            2           2  0.970444  0.029556  \n73               0            2           2  0.970244  0.029756  \n80               0            2           2  0.970244  0.029756  \n22               0            2           2  0.969920  0.030080  \n124              0            2           2  0.968750  0.031250  \n26               0            2           2  0.968354  0.031646  \n180              0            2           2  0.967620  0.032379  \n186              0            3           2  0.964862  0.035138  \n75               0            2           2  0.963219  0.036781  \n138              0            2           2  0.962472  0.037528  \n1                2            2           2  0.959171  0.040829  \n69               0            3           2  0.957147  0.042853  \n23               0            2           2  0.954219  0.045781  \n21               0            2           2  0.954219  0.045781  \n170              0            2           2  0.940170  0.059830  \n29               0            3           2  0.939015  0.060985  \n158              0            2           2  0.935458  0.064542  \n51               0            2           2  0.930739  0.069261  \n106              0            2           2  0.926609  0.073391  \n122              1            2           2  0.923845  0.076155  \n150              2            2           2  0.910878  0.089122  \n141              8            3           2  0.905935  0.094065  \n167              0            2           2  0.902430  0.097570  \n48               0            2           2  0.889448  0.110552  \n65               9            3           2  0.883852  0.116148  \n43               0            2           2  0.880426  0.119574  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>job_applicant_id</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>marriage_status</th>\n      <th>languages</th>\n      <th>contract_type</th>\n      <th>degree</th>\n      <th>average_gpa</th>\n      <th>skill</th>\n      <th>num_prev_company</th>\n      <th>work_interval</th>\n      <th>steps_title</th>\n      <th>prediction</th>\n      <th>Prob_0</th>\n      <th>Prob_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>112</th>\n      <td>44253</td>\n      <td>0.0</td>\n      <td>41.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.997357</td>\n      <td>0.002643</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>47259</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.994886</td>\n      <td>0.005114</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>9280</td>\n      <td>NaN</td>\n      <td>27.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.994599</td>\n      <td>0.005402</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>46145</td>\n      <td>0.0</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.993616</td>\n      <td>0.006384</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>46135</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.992919</td>\n      <td>0.007081</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>3665</td>\n      <td>NaN</td>\n      <td>32.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.991989</td>\n      <td>0.008011</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>29650</td>\n      <td>NaN</td>\n      <td>36.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.991203</td>\n      <td>0.008797</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>46207</td>\n      <td>0.0</td>\n      <td>37.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.990516</td>\n      <td>0.009484</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>3419</td>\n      <td>NaN</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.987167</td>\n      <td>0.012833</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>8831</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>17.700</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.986791</td>\n      <td>0.013209</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>46335</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.985937</td>\n      <td>0.014063</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>46036</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>16.000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.984359</td>\n      <td>0.015641</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19161</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.983733</td>\n      <td>0.016267</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>46164</td>\n      <td>0.0</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.982425</td>\n      <td>0.017575</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>46809</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>18.000</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.982358</td>\n      <td>0.017642</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>46422</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>17.180</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.981904</td>\n      <td>0.018096</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>8822</td>\n      <td>NaN</td>\n      <td>37.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>8</td>\n      <td>14</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.980961</td>\n      <td>0.019039</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>9086</td>\n      <td>NaN</td>\n      <td>34.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.980165</td>\n      <td>0.019835</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>46083</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>19.200</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.979746</td>\n      <td>0.020254</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>2239</td>\n      <td>NaN</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>3</td>\n      <td>20</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.979535</td>\n      <td>0.020465</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>49263</td>\n      <td>NaN</td>\n      <td>38.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.977627</td>\n      <td>0.022373</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>3301</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>16.400</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.976412</td>\n      <td>0.023588</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>50512</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>17.500</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.975682</td>\n      <td>0.024317</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>9303</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>13.000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.972087</td>\n      <td>0.027913</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>46034</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>14.000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.970444</td>\n      <td>0.029556</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>46099</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>18.265</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.970244</td>\n      <td>0.029756</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>46105</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>16.500</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.970244</td>\n      <td>0.029756</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>46028</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>18.000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.969920</td>\n      <td>0.030080</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>46102</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>14.000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.968750</td>\n      <td>0.031250</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>3597</td>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.968354</td>\n      <td>0.031646</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>46562</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.967620</td>\n      <td>0.032379</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>8265</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.964862</td>\n      <td>0.035138</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>46031</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>16.325</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.963219</td>\n      <td>0.036781</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>46384</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>14.800</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.962472</td>\n      <td>0.037528</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1845</td>\n      <td>NaN</td>\n      <td>42.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.959171</td>\n      <td>0.040829</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>20580</td>\n      <td>0.0</td>\n      <td>37.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.957147</td>\n      <td>0.042853</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>46129</td>\n      <td>0.0</td>\n      <td>28.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.954219</td>\n      <td>0.045781</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>46381</td>\n      <td>0.0</td>\n      <td>28.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.954219</td>\n      <td>0.045781</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>46956</td>\n      <td>NaN</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.940170</td>\n      <td>0.059830</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>22443</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.939015</td>\n      <td>0.060985</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>46650</td>\n      <td>NaN</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.935458</td>\n      <td>0.064542</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>45788</td>\n      <td>NaN</td>\n      <td>40.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.930739</td>\n      <td>0.069261</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>40811</td>\n      <td>NaN</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>16.720</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.926609</td>\n      <td>0.073391</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>2189</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>16.000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.923845</td>\n      <td>0.076155</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>1180</td>\n      <td>NaN</td>\n      <td>45.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.910878</td>\n      <td>0.089122</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>6251</td>\n      <td>NaN</td>\n      <td>44.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.905935</td>\n      <td>0.094065</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>3410</td>\n      <td>0.0</td>\n      <td>48.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.902430</td>\n      <td>0.097570</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>46879</td>\n      <td>0.0</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.889448</td>\n      <td>0.110552</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>24676</td>\n      <td>0.0</td>\n      <td>38.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0.883852</td>\n      <td>0.116148</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>42128</td>\n      <td>NaN</td>\n      <td>31.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.880426</td>\n      <td>0.119574</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, KFold, cross_val_predict, \\\n",
    "    cross_validate\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "with open('pss.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "password = lines[0]\n",
    "db = lines[1]\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=password,\n",
    "    database=db,\n",
    "    use_pure=True\n",
    ")\n",
    "\n",
    "my_cursor = mydb.cursor()\n",
    "steps_title_list = []\n",
    "d_steps_title = {}\n",
    "university_name_list = []\n",
    "d_uni_name = {}\n",
    "\n",
    "# def convert_nans(df):\n",
    "#     # job_applicant_id,gender,age,marriage_status,language,degree,skill,num_prev_company,work_interval,steps_title\n",
    "#     df['steps_title'] = df['steps_title'].fillna(6)\n",
    "#     df['age'] = df['age'].fillna(-1)\n",
    "#     df['skill'] = df['skill'].fillna(-1)\n",
    "#     df['marriage_status'] = df['marriage_status'].fillna(-1)\n",
    "#     # df['language'] = df['language'].fillna(-1)\n",
    "#     # df['job_contract_type'] = df['job_contract_type'].fillna(-1)\n",
    "#     df['gender'] = df['gender'].fillna(-1)\n",
    "#     df['degree'] = df['degree'].fillna(-1)\n",
    "#     df['skill'] = df['skill'].fillna(-1)\n",
    "#     df['num_prev_company'] = df['num_prev_company'].fillna(-1)\n",
    "#     df['work_interval'] = df['work_interval'].fillna(-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "my_cursor.execute('select distinct steps_title from useful_data')\n",
    "for item in my_cursor:\n",
    "    steps_title_list.append(item)\n",
    "\n",
    "\n",
    "for title in steps_title_list:\n",
    "    if title[0] == 'نیازمند تعیین وضعیت':\n",
    "        d_steps_title[title[0]] = 0\n",
    "    elif title[0] == 'تایید برای مصاحبه':\n",
    "        d_steps_title[title[0]] = 1\n",
    "    elif title[0] == 'استخدام شده':\n",
    "        d_steps_title[title[0]] = 2\n",
    "    elif title[0] == 'رد شده':\n",
    "        d_steps_title[title[0]] = 3\n",
    "    elif title[0] == 'انصراف از مصاحبه':\n",
    "        d_steps_title[title[0]] = 4\n",
    "    else:\n",
    "        d_steps_title[title[0]] = 6\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train.head(10)\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_train['steps_title'] = df_train['steps_title'].map(d_steps_title)\n",
    "df_test['steps_title'] = df_test['steps_title'].map(d_steps_title)\n",
    "# convert_nans(df_train)\n",
    "# convert_nans(df_test)\n",
    "# [2 , 4 , 5 , 6 , 7 ,10]\n",
    "x_train =df_train[df_train.columns[1:11]]\n",
    "x_test = df_test[df_test.columns[1:11]]\n",
    "y_test = df_test['steps_title']\n",
    "y_train = df_train['steps_title']\n",
    "kfold = KFold(n_splits=10)\n",
    "features_train = df_train.columns[1:11]\n",
    "# clf = RandomForestClassifier(n_jobs=2 , random_state=0)\n",
    "clf = xgb.XGBClassifier(seed=42, subsample=0.9)\n",
    "cv_results = cross_val_score(clf,x_train , y_train,cv=kfold , scoring='accuracy')\n",
    "output = cross_validate(clf, x_train, y_train, cv=10, scoring = 'accuracy', return_estimator =True)\n",
    "y_pred = cross_val_predict(clf,x_test,y_test,cv=10)\n",
    "proba = cross_val_predict(clf,x_test,y_test,cv=10, method='predict_proba')\n",
    "clf.fit(x_train , y_train , verbose=0, eval_set =[(x_test, y_test)])\n",
    "# clf.fit(x_train , y_train)\n",
    "results = (cv_results.mean(),cv_results.std())\n",
    "print(results)\n",
    "print(\"accuracy : \", accuracy_score(y_test, y_pred))\n",
    "print(pd.crosstab(y_test,y_pred))\n",
    "df_test[\"prediction\"] = y_pred\n",
    "# for idx,estimator in enumerate(output['estimator']):\n",
    "#     print(\"Features sorted by their score for estimator {}:\".format(idx))\n",
    "#     feature_importances = pd.DataFrame(estimator.feature_importances_,\n",
    "#                                         index= features_train,\n",
    "#                                         columns=['importance']).sort_values('importance', ascending=False)\n",
    "#     print(feature_importances)\n",
    "\n",
    "\n",
    "proba_0 = []\n",
    "proba_1 = []\n",
    "type(proba)\n",
    "for prob0 , prob1 in proba:\n",
    "    proba_0.append(float(prob0))\n",
    "    proba_1.append(float(prob1))\n",
    "df_test['Prob_0'] = proba_0\n",
    "df_test['Prob_1'] = proba_1\n",
    "final_df = df_test.sort_values(by=['Prob_0'], ascending=False)\n",
    "print(final_df.loc[final_df['steps_title'] == final_df['prediction'] , 'job_applicant_id'].iloc[0:9])\n",
    "# print(final_df.loc['job_applicant_id'].iloc[0:9])\n",
    "#\n",
    "final_df.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}