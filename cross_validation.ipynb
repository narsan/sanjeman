{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.7712765957446809\n",
      "col_0         2   3\n",
      "steps_title        \n",
      "2            71  23\n",
      "3            20  74\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>job_applicant_id</th>\n      <th>Prob_0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>46078</td>\n      <td>0.998020</td>\n    </tr>\n    <tr>\n      <td>3432</td>\n      <td>0.997730</td>\n    </tr>\n    <tr>\n      <td>46021</td>\n      <td>0.997584</td>\n    </tr>\n    <tr>\n      <td>46119</td>\n      <td>0.996399</td>\n    </tr>\n    <tr>\n      <td>46097</td>\n      <td>0.995586</td>\n    </tr>\n    <tr>\n      <td>47211</td>\n      <td>0.995352</td>\n    </tr>\n    <tr>\n      <td>32188</td>\n      <td>0.994726</td>\n    </tr>\n    <tr>\n      <td>43721</td>\n      <td>0.993912</td>\n    </tr>\n    <tr>\n      <td>46185</td>\n      <td>0.993615</td>\n    </tr>\n    <tr>\n      <td>43185</td>\n      <td>0.993067</td>\n    </tr>\n    <tr>\n      <td>9822</td>\n      <td>0.993067</td>\n    </tr>\n    <tr>\n      <td>46074</td>\n      <td>0.993056</td>\n    </tr>\n    <tr>\n      <td>9436</td>\n      <td>0.992712</td>\n    </tr>\n    <tr>\n      <td>43963</td>\n      <td>0.991889</td>\n    </tr>\n    <tr>\n      <td>46503</td>\n      <td>0.991842</td>\n    </tr>\n    <tr>\n      <td>42202</td>\n      <td>0.991842</td>\n    </tr>\n    <tr>\n      <td>4567</td>\n      <td>0.989772</td>\n    </tr>\n    <tr>\n      <td>14148</td>\n      <td>0.989339</td>\n    </tr>\n    <tr>\n      <td>41732</td>\n      <td>0.989339</td>\n    </tr>\n    <tr>\n      <td>10768</td>\n      <td>0.989339</td>\n    </tr>\n    <tr>\n      <td>3421</td>\n      <td>0.989339</td>\n    </tr>\n    <tr>\n      <td>43484</td>\n      <td>0.989339</td>\n    </tr>\n    <tr>\n      <td>52112</td>\n      <td>0.988997</td>\n    </tr>\n    <tr>\n      <td>46028</td>\n      <td>0.988618</td>\n    </tr>\n    <tr>\n      <td>46374</td>\n      <td>0.988373</td>\n    </tr>\n    <tr>\n      <td>9206</td>\n      <td>0.987772</td>\n    </tr>\n    <tr>\n      <td>3597</td>\n      <td>0.987303</td>\n    </tr>\n    <tr>\n      <td>9245</td>\n      <td>0.986934</td>\n    </tr>\n    <tr>\n      <td>46145</td>\n      <td>0.986285</td>\n    </tr>\n    <tr>\n      <td>46333</td>\n      <td>0.985411</td>\n    </tr>\n    <tr>\n      <td>46403</td>\n      <td>0.984848</td>\n    </tr>\n    <tr>\n      <td>46275</td>\n      <td>0.984769</td>\n    </tr>\n    <tr>\n      <td>46325</td>\n      <td>0.984494</td>\n    </tr>\n    <tr>\n      <td>46582</td>\n      <td>0.983307</td>\n    </tr>\n    <tr>\n      <td>46620</td>\n      <td>0.980467</td>\n    </tr>\n    <tr>\n      <td>3462</td>\n      <td>0.979610</td>\n    </tr>\n    <tr>\n      <td>46515</td>\n      <td>0.979054</td>\n    </tr>\n    <tr>\n      <td>41916</td>\n      <td>0.978457</td>\n    </tr>\n    <tr>\n      <td>46958</td>\n      <td>0.977162</td>\n    </tr>\n    <tr>\n      <td>46529</td>\n      <td>0.977162</td>\n    </tr>\n    <tr>\n      <td>3270</td>\n      <td>0.976793</td>\n    </tr>\n    <tr>\n      <td>51668</td>\n      <td>0.974655</td>\n    </tr>\n    <tr>\n      <td>46105</td>\n      <td>0.974402</td>\n    </tr>\n    <tr>\n      <td>10194</td>\n      <td>0.967868</td>\n    </tr>\n    <tr>\n      <td>38275</td>\n      <td>0.966663</td>\n    </tr>\n    <tr>\n      <td>47897</td>\n      <td>0.962408</td>\n    </tr>\n    <tr>\n      <td>52042</td>\n      <td>0.952806</td>\n    </tr>\n    <tr>\n      <td>7194</td>\n      <td>0.946952</td>\n    </tr>\n    <tr>\n      <td>49013</td>\n      <td>0.942904</td>\n    </tr>\n    <tr>\n      <td>9775</td>\n      <td>0.939817</td>\n    </tr>\n    <tr>\n      <td>46384</td>\n      <td>0.938173</td>\n    </tr>\n    <tr>\n      <td>29764</td>\n      <td>0.923247</td>\n    </tr>\n    <tr>\n      <td>43912</td>\n      <td>0.919278</td>\n    </tr>\n    <tr>\n      <td>53143</td>\n      <td>0.906800</td>\n    </tr>\n    <tr>\n      <td>53626</td>\n      <td>0.906800</td>\n    </tr>\n    <tr>\n      <td>50244</td>\n      <td>0.902588</td>\n    </tr>\n    <tr>\n      <td>2189</td>\n      <td>0.900863</td>\n    </tr>\n    <tr>\n      <td>52179</td>\n      <td>0.900243</td>\n    </tr>\n    <tr>\n      <td>54626</td>\n      <td>0.898037</td>\n    </tr>\n    <tr>\n      <td>51038</td>\n      <td>0.893408</td>\n    </tr>\n    <tr>\n      <td>12892</td>\n      <td>0.888305</td>\n    </tr>\n    <tr>\n      <td>51505</td>\n      <td>0.888305</td>\n    </tr>\n    <tr>\n      <td>51088</td>\n      <td>0.887062</td>\n    </tr>\n    <tr>\n      <td>53039</td>\n      <td>0.887062</td>\n    </tr>\n    <tr>\n      <td>44386</td>\n      <td>0.877980</td>\n    </tr>\n    <tr>\n      <td>52681</td>\n      <td>0.877980</td>\n    </tr>\n    <tr>\n      <td>52693</td>\n      <td>0.877980</td>\n    </tr>\n    <tr>\n      <td>1003</td>\n      <td>0.844318</td>\n    </tr>\n    <tr>\n      <td>52964</td>\n      <td>0.815062</td>\n    </tr>\n    <tr>\n      <td>51405</td>\n      <td>0.791743</td>\n    </tr>\n    <tr>\n      <td>50902</td>\n      <td>0.788797</td>\n    </tr>\n    <tr>\n      <td>45094</td>\n      <td>0.780300</td>\n    </tr>\n    <tr>\n      <td>11360</td>\n      <td>0.777090</td>\n    </tr>\n    <tr>\n      <td>16499</td>\n      <td>0.734900</td>\n    </tr>\n    <tr>\n      <td>52381</td>\n      <td>0.731402</td>\n    </tr>\n    <tr>\n      <td>47638</td>\n      <td>0.722894</td>\n    </tr>\n    <tr>\n      <td>44809</td>\n      <td>0.717972</td>\n    </tr>\n    <tr>\n      <td>42128</td>\n      <td>0.715760</td>\n    </tr>\n    <tr>\n      <td>42178</td>\n      <td>0.713414</td>\n    </tr>\n    <tr>\n      <td>41653</td>\n      <td>0.709803</td>\n    </tr>\n    <tr>\n      <td>34903</td>\n      <td>0.666430</td>\n    </tr>\n    <tr>\n      <td>15743</td>\n      <td>0.664270</td>\n    </tr>\n    <tr>\n      <td>39307</td>\n      <td>0.664270</td>\n    </tr>\n    <tr>\n      <td>34638</td>\n      <td>0.664270</td>\n    </tr>\n    <tr>\n      <td>22100</td>\n      <td>0.642648</td>\n    </tr>\n    <tr>\n      <td>45114</td>\n      <td>0.630772</td>\n    </tr>\n    <tr>\n      <td>20355</td>\n      <td>0.561718</td>\n    </tr>\n    <tr>\n      <td>29466</td>\n      <td>0.561718</td>\n    </tr>\n    <tr>\n      <td>47568</td>\n      <td>0.561718</td>\n    </tr>\n    <tr>\n      <td>8919</td>\n      <td>0.560814</td>\n    </tr>\n    <tr>\n      <td>925</td>\n      <td>0.502202</td>\n    </tr>\n    <tr>\n      <td>20773</td>\n      <td>0.488735</td>\n    </tr>\n    <tr>\n      <td>43814</td>\n      <td>0.488735</td>\n    </tr>\n    <tr>\n      <td>6912</td>\n      <td>0.457218</td>\n    </tr>\n    <tr>\n      <td>1026</td>\n      <td>0.443156</td>\n    </tr>\n    <tr>\n      <td>50016</td>\n      <td>0.442910</td>\n    </tr>\n    <tr>\n      <td>49254</td>\n      <td>0.442910</td>\n    </tr>\n    <tr>\n      <td>20744</td>\n      <td>0.435832</td>\n    </tr>\n    <tr>\n      <td>50996</td>\n      <td>0.434622</td>\n    </tr>\n    <tr>\n      <td>26632</td>\n      <td>0.406755</td>\n    </tr>\n    <tr>\n      <td>6413</td>\n      <td>0.405826</td>\n    </tr>\n    <tr>\n      <td>6187</td>\n      <td>0.403920</td>\n    </tr>\n    <tr>\n      <td>31894</td>\n      <td>0.393617</td>\n    </tr>\n    <tr>\n      <td>5749</td>\n      <td>0.392938</td>\n    </tr>\n    <tr>\n      <td>8759</td>\n      <td>0.390100</td>\n    </tr>\n    <tr>\n      <td>913</td>\n      <td>0.387449</td>\n    </tr>\n    <tr>\n      <td>41675</td>\n      <td>0.387449</td>\n    </tr>\n    <tr>\n      <td>791</td>\n      <td>0.387449</td>\n    </tr>\n    <tr>\n      <td>18308</td>\n      <td>0.387449</td>\n    </tr>\n    <tr>\n      <td>53385</td>\n      <td>0.349034</td>\n    </tr>\n    <tr>\n      <td>10876</td>\n      <td>0.336945</td>\n    </tr>\n    <tr>\n      <td>6972</td>\n      <td>0.330068</td>\n    </tr>\n    <tr>\n      <td>19685</td>\n      <td>0.323522</td>\n    </tr>\n    <tr>\n      <td>18625</td>\n      <td>0.287840</td>\n    </tr>\n    <tr>\n      <td>36954</td>\n      <td>0.286458</td>\n    </tr>\n    <tr>\n      <td>30887</td>\n      <td>0.282412</td>\n    </tr>\n    <tr>\n      <td>8472</td>\n      <td>0.264981</td>\n    </tr>\n    <tr>\n      <td>44511</td>\n      <td>0.257600</td>\n    </tr>\n    <tr>\n      <td>52152</td>\n      <td>0.252768</td>\n    </tr>\n    <tr>\n      <td>52776</td>\n      <td>0.249200</td>\n    </tr>\n    <tr>\n      <td>42158</td>\n      <td>0.248973</td>\n    </tr>\n    <tr>\n      <td>46250</td>\n      <td>0.248973</td>\n    </tr>\n    <tr>\n      <td>24344</td>\n      <td>0.221307</td>\n    </tr>\n    <tr>\n      <td>18279</td>\n      <td>0.194718</td>\n    </tr>\n    <tr>\n      <td>12317</td>\n      <td>0.183909</td>\n    </tr>\n    <tr>\n      <td>1391</td>\n      <td>0.177436</td>\n    </tr>\n    <tr>\n      <td>23256</td>\n      <td>0.161548</td>\n    </tr>\n    <tr>\n      <td>52281</td>\n      <td>0.148321</td>\n    </tr>\n    <tr>\n      <td>9669</td>\n      <td>0.147397</td>\n    </tr>\n    <tr>\n      <td>21177</td>\n      <td>0.132754</td>\n    </tr>\n    <tr>\n      <td>53230</td>\n      <td>0.112983</td>\n    </tr>\n    <tr>\n      <td>15989</td>\n      <td>0.110304</td>\n    </tr>\n    <tr>\n      <td>23227</td>\n      <td>0.110304</td>\n    </tr>\n    <tr>\n      <td>50949</td>\n      <td>0.105330</td>\n    </tr>\n    <tr>\n      <td>31249</td>\n      <td>0.091690</td>\n    </tr>\n    <tr>\n      <td>51248</td>\n      <td>0.087803</td>\n    </tr>\n    <tr>\n      <td>25305</td>\n      <td>0.082610</td>\n    </tr>\n    <tr>\n      <td>26072</td>\n      <td>0.067423</td>\n    </tr>\n    <tr>\n      <td>26606</td>\n      <td>0.063172</td>\n    </tr>\n    <tr>\n      <td>8475</td>\n      <td>0.061616</td>\n    </tr>\n    <tr>\n      <td>50418</td>\n      <td>0.051382</td>\n    </tr>\n    <tr>\n      <td>30873</td>\n      <td>0.049102</td>\n    </tr>\n    <tr>\n      <td>52891</td>\n      <td>0.047489</td>\n    </tr>\n    <tr>\n      <td>35274</td>\n      <td>0.045110</td>\n    </tr>\n    <tr>\n      <td>37857</td>\n      <td>0.044695</td>\n    </tr>\n    <tr>\n      <td>18736</td>\n      <td>0.043030</td>\n    </tr>\n    <tr>\n      <td>20620</td>\n      <td>0.042732</td>\n    </tr>\n    <tr>\n      <td>51554</td>\n      <td>0.041740</td>\n    </tr>\n    <tr>\n      <td>38671</td>\n      <td>0.040063</td>\n    </tr>\n    <tr>\n      <td>24843</td>\n      <td>0.039845</td>\n    </tr>\n    <tr>\n      <td>30905</td>\n      <td>0.039123</td>\n    </tr>\n    <tr>\n      <td>28671</td>\n      <td>0.038235</td>\n    </tr>\n    <tr>\n      <td>32022</td>\n      <td>0.032605</td>\n    </tr>\n    <tr>\n      <td>16881</td>\n      <td>0.031130</td>\n    </tr>\n    <tr>\n      <td>20045</td>\n      <td>0.028737</td>\n    </tr>\n    <tr>\n      <td>50034</td>\n      <td>0.028406</td>\n    </tr>\n    <tr>\n      <td>24647</td>\n      <td>0.027045</td>\n    </tr>\n    <tr>\n      <td>6731</td>\n      <td>0.024308</td>\n    </tr>\n    <tr>\n      <td>23379</td>\n      <td>0.021892</td>\n    </tr>\n    <tr>\n      <td>17187</td>\n      <td>0.021502</td>\n    </tr>\n    <tr>\n      <td>12590</td>\n      <td>0.021389</td>\n    </tr>\n    <tr>\n      <td>48242</td>\n      <td>0.021165</td>\n    </tr>\n    <tr>\n      <td>16904</td>\n      <td>0.019978</td>\n    </tr>\n    <tr>\n      <td>14466</td>\n      <td>0.019276</td>\n    </tr>\n    <tr>\n      <td>38294</td>\n      <td>0.017972</td>\n    </tr>\n    <tr>\n      <td>24637</td>\n      <td>0.015568</td>\n    </tr>\n    <tr>\n      <td>17337</td>\n      <td>0.013948</td>\n    </tr>\n    <tr>\n      <td>34603</td>\n      <td>0.012793</td>\n    </tr>\n    <tr>\n      <td>41458</td>\n      <td>0.012519</td>\n    </tr>\n    <tr>\n      <td>17023</td>\n      <td>0.011686</td>\n    </tr>\n    <tr>\n      <td>38123</td>\n      <td>0.011390</td>\n    </tr>\n    <tr>\n      <td>41024</td>\n      <td>0.011116</td>\n    </tr>\n    <tr>\n      <td>26543</td>\n      <td>0.010891</td>\n    </tr>\n    <tr>\n      <td>14733</td>\n      <td>0.008665</td>\n    </tr>\n    <tr>\n      <td>25038</td>\n      <td>0.008562</td>\n    </tr>\n    <tr>\n      <td>37436</td>\n      <td>0.008257</td>\n    </tr>\n    <tr>\n      <td>39052</td>\n      <td>0.008144</td>\n    </tr>\n    <tr>\n      <td>1161</td>\n      <td>0.007036</td>\n    </tr>\n    <tr>\n      <td>30510</td>\n      <td>0.006781</td>\n    </tr>\n    <tr>\n      <td>10165</td>\n      <td>0.004912</td>\n    </tr>\n    <tr>\n      <td>32894</td>\n      <td>0.004828</td>\n    </tr>\n    <tr>\n      <td>6869</td>\n      <td>0.004227</td>\n    </tr>\n    <tr>\n      <td>33763</td>\n      <td>0.003619</td>\n    </tr>\n    <tr>\n      <td>31537</td>\n      <td>0.003496</td>\n    </tr>\n    <tr>\n      <td>27583</td>\n      <td>0.003421</td>\n    </tr>\n    <tr>\n      <td>39571</td>\n      <td>0.002549</td>\n    </tr>\n    <tr>\n      <td>35898</td>\n      <td>0.001604</td>\n    </tr>\n    <tr>\n      <td>18715</td>\n      <td>0.001252</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score,KFold, cross_val_predict,cross_validate\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "proba_0 = []\n",
    "proba_1 = []\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train.head(10)\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "x_train =df_train[df_train.columns[1:11]]\n",
    "x_test = df_test[df_test.columns[1:11]]\n",
    "y_test = df_test['steps_title']\n",
    "y_train = df_train['steps_title']\n",
    "kfold = KFold(n_splits=10)\n",
    "features_train = df_train.columns[1:11]\n",
    "clf = xgb.XGBClassifier(seed=42, subsample=0.9)\n",
    "cv_results = cross_val_score(clf,x_train , y_train,cv=kfold , scoring='accuracy')\n",
    "output = cross_validate(clf, x_train, y_train, cv=10, scoring = 'accuracy', return_estimator =True)\n",
    "y_pred = cross_val_predict(clf,x_test,y_test,cv=10)\n",
    "proba = cross_val_predict(clf,x_test,y_test,cv=10, method='predict_proba')\n",
    "clf.fit(x_train , y_train , verbose=0, eval_set =[(x_test, y_test)])\n",
    "print(\"accuracy : \", accuracy_score(y_test, y_pred))\n",
    "print(pd.crosstab(y_test,y_pred))\n",
    "df_test[\"prediction\"] = y_pred\n",
    "\n",
    "for prob0 , prob1 in proba:\n",
    "    proba_0.append(float(prob0))\n",
    "    proba_1.append(float(prob1))\n",
    "df_test['Prob_0'] = proba_0\n",
    "df_test['Prob_1'] = proba_1\n",
    "final_df = (df_test.sort_values(by=['Prob_0'], ascending=False)).iloc[:,[0 , 13]]\n",
    "HTML(final_df.to_html(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}