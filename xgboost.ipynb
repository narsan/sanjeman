{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:06:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.65596\n",
      "[1]\tvalidation_0-logloss:0.67051\n",
      "[2]\tvalidation_0-logloss:0.70649\n",
      "[3]\tvalidation_0-logloss:0.74357\n",
      "[4]\tvalidation_0-logloss:0.78858\n",
      "[5]\tvalidation_0-logloss:0.83535\n",
      "[6]\tvalidation_0-logloss:0.87808\n",
      "[7]\tvalidation_0-logloss:0.91593\n",
      "[8]\tvalidation_0-logloss:0.95526\n",
      "[9]\tvalidation_0-logloss:0.99143\n",
      "[10]\tvalidation_0-logloss:1.03003\n",
      "[11]\tvalidation_0-logloss:1.06024\n",
      "[12]\tvalidation_0-logloss:1.08495\n",
      "[13]\tvalidation_0-logloss:1.11016\n",
      "[14]\tvalidation_0-logloss:1.13344\n",
      "[15]\tvalidation_0-logloss:1.15212\n",
      "[16]\tvalidation_0-logloss:1.17068\n",
      "[17]\tvalidation_0-logloss:1.18209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\tvalidation_0-logloss:1.19227\n",
      "[19]\tvalidation_0-logloss:1.19886\n",
      "[20]\tvalidation_0-logloss:1.20152\n",
      "[21]\tvalidation_0-logloss:1.20461\n",
      "[22]\tvalidation_0-logloss:1.20616\n",
      "[23]\tvalidation_0-logloss:1.20424\n",
      "[24]\tvalidation_0-logloss:1.20953\n",
      "[25]\tvalidation_0-logloss:1.21118\n",
      "[26]\tvalidation_0-logloss:1.21264\n",
      "[27]\tvalidation_0-logloss:1.21980\n",
      "[28]\tvalidation_0-logloss:1.22172\n",
      "[29]\tvalidation_0-logloss:1.22246\n",
      "[30]\tvalidation_0-logloss:1.22679\n",
      "[31]\tvalidation_0-logloss:1.22756\n",
      "[32]\tvalidation_0-logloss:1.22924\n",
      "[33]\tvalidation_0-logloss:1.23229\n",
      "[34]\tvalidation_0-logloss:1.23246\n",
      "[35]\tvalidation_0-logloss:1.23289\n",
      "[36]\tvalidation_0-logloss:1.23543\n",
      "[37]\tvalidation_0-logloss:1.24250\n",
      "[38]\tvalidation_0-logloss:1.24420\n",
      "[39]\tvalidation_0-logloss:1.24421\n",
      "[40]\tvalidation_0-logloss:1.24615\n",
      "[41]\tvalidation_0-logloss:1.24541\n",
      "[42]\tvalidation_0-logloss:1.24648\n",
      "[43]\tvalidation_0-logloss:1.24759\n",
      "[44]\tvalidation_0-logloss:1.24686\n",
      "[45]\tvalidation_0-logloss:1.24727\n",
      "[46]\tvalidation_0-logloss:1.24536\n",
      "[47]\tvalidation_0-logloss:1.24813\n",
      "[48]\tvalidation_0-logloss:1.24761\n",
      "[49]\tvalidation_0-logloss:1.24840\n",
      "[50]\tvalidation_0-logloss:1.24890\n",
      "[51]\tvalidation_0-logloss:1.25033\n",
      "[52]\tvalidation_0-logloss:1.25320\n",
      "[53]\tvalidation_0-logloss:1.25282\n",
      "[54]\tvalidation_0-logloss:1.25421\n",
      "[55]\tvalidation_0-logloss:1.25487\n",
      "[56]\tvalidation_0-logloss:1.25514\n",
      "[57]\tvalidation_0-logloss:1.25497\n",
      "[58]\tvalidation_0-logloss:1.25537\n",
      "[59]\tvalidation_0-logloss:1.25725\n",
      "[60]\tvalidation_0-logloss:1.25884\n",
      "[61]\tvalidation_0-logloss:1.26032\n",
      "[62]\tvalidation_0-logloss:1.26116\n",
      "[63]\tvalidation_0-logloss:1.26008\n",
      "[64]\tvalidation_0-logloss:1.26477\n",
      "[65]\tvalidation_0-logloss:1.26705\n",
      "[66]\tvalidation_0-logloss:1.26908\n",
      "[67]\tvalidation_0-logloss:1.27090\n",
      "[68]\tvalidation_0-logloss:1.27004\n",
      "[69]\tvalidation_0-logloss:1.26944\n",
      "[70]\tvalidation_0-logloss:1.27174\n",
      "[71]\tvalidation_0-logloss:1.27209\n",
      "[72]\tvalidation_0-logloss:1.27900\n",
      "[73]\tvalidation_0-logloss:1.28105\n",
      "[74]\tvalidation_0-logloss:1.28186\n",
      "[75]\tvalidation_0-logloss:1.28314\n",
      "[76]\tvalidation_0-logloss:1.28352\n",
      "[77]\tvalidation_0-logloss:1.28299\n",
      "[78]\tvalidation_0-logloss:1.28564\n",
      "[79]\tvalidation_0-logloss:1.28586\n",
      "[80]\tvalidation_0-logloss:1.28846\n",
      "[81]\tvalidation_0-logloss:1.28817\n",
      "[82]\tvalidation_0-logloss:1.28857\n",
      "[83]\tvalidation_0-logloss:1.28896\n",
      "[84]\tvalidation_0-logloss:1.28834\n",
      "[85]\tvalidation_0-logloss:1.28990\n",
      "[86]\tvalidation_0-logloss:1.28919\n",
      "[87]\tvalidation_0-logloss:1.28966\n",
      "[88]\tvalidation_0-logloss:1.28837\n",
      "[89]\tvalidation_0-logloss:1.28846\n",
      "[90]\tvalidation_0-logloss:1.29018\n",
      "[91]\tvalidation_0-logloss:1.29000\n",
      "[92]\tvalidation_0-logloss:1.28845\n",
      "[93]\tvalidation_0-logloss:1.28825\n",
      "[94]\tvalidation_0-logloss:1.28993\n",
      "[95]\tvalidation_0-logloss:1.29016\n",
      "[96]\tvalidation_0-logloss:1.29025\n",
      "[97]\tvalidation_0-logloss:1.29107\n",
      "[98]\tvalidation_0-logloss:1.29144\n",
      "[99]\tvalidation_0-logloss:1.28966\n",
      "[19:06:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:06:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:06:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:06:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:06:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:06:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:06:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:06:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:06:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:06:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/narges/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Expecting 2 dimensional numpy.ndarray, got: ', (188,))",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/5w/d0clwdys1wb9tf0zzmmr3v7h0000gn/T/ipykernel_21733/3969733680.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m \u001B[0;31m# y_pred=cross_val_predict(clf,x_test,y_test,cv=10)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 85\u001B[0;31m \u001B[0mplot_confusion_matrix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclf_xgb\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0my_pred\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     86\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[0;31m# print(\"accuracy : \", accuracy_score(y_test, y_pred))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/sklearn/metrics/_plot/confusion_matrix.py\u001B[0m in \u001B[0;36mplot_confusion_matrix\u001B[0;34m(estimator, X, y_true, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar)\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"plot_confusion_matrix only supports classifiers\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 263\u001B[0;31m     \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mestimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    264\u001B[0m     cm = confusion_matrix(y_true, y_pred, sample_weight=sample_weight,\n\u001B[1;32m    265\u001B[0m                           labels=labels, normalize=normalize)\n",
      "\u001B[0;32m~/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001B[0m\n\u001B[1;32m   1207\u001B[0m         \u001B[0miteration_range\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mTuple\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1208\u001B[0m     ):\n\u001B[0;32m-> 1209\u001B[0;31m         class_probs = super().predict(\n\u001B[0m\u001B[1;32m   1210\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1211\u001B[0m             \u001B[0moutput_margin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_margin\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/sklearn.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001B[0m\n\u001B[1;32m    834\u001B[0m                 \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    835\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 836\u001B[0;31m         test = DMatrix(\n\u001B[0m\u001B[1;32m    837\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbase_margin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbase_margin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmissing\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissing\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnthread\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    838\u001B[0m         )\n",
      "\u001B[0;32m~/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/core.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    434\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    435\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 436\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    437\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/core.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001B[0m\n\u001B[1;32m    539\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdispatch_data_backend\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    540\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 541\u001B[0;31m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001B[0m\u001B[1;32m    542\u001B[0m             \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    543\u001B[0m             \u001B[0mmissing\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissing\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/data.py\u001B[0m in \u001B[0;36mdispatch_data_backend\u001B[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001B[0m\n\u001B[1;32m    574\u001B[0m                                feature_names, feature_types)\n\u001B[1;32m    575\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_pandas_series\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 576\u001B[0;31m         return _from_pandas_series(data, missing, threads, feature_names,\n\u001B[0m\u001B[1;32m    577\u001B[0m                                    feature_types)\n\u001B[1;32m    578\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_cudf_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/data.py\u001B[0m in \u001B[0;36m_from_pandas_series\u001B[0;34m(data, missing, nthread, feature_types, feature_names)\u001B[0m\n\u001B[1;32m    279\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_from_pandas_series\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmissing\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeature_types\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeature_names\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 281\u001B[0;31m     return _from_numpy_array(data.values.astype('float'), missing, nthread,\n\u001B[0m\u001B[1;32m    282\u001B[0m                              feature_names, feature_types)\n\u001B[1;32m    283\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/data.py\u001B[0m in \u001B[0;36m_from_numpy_array\u001B[0;34m(data, missing, nthread, feature_names, feature_types)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m     \"\"\"\n\u001B[0;32m--> 161\u001B[0;31m     \u001B[0mflatten\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndarray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_transform_np_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    162\u001B[0m     \u001B[0mhandle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mc_void_p\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    163\u001B[0m     _check_call(_LIB.XGDMatrixCreateFromMat_omp(\n",
      "\u001B[0;32m~/PycharmProjects/sanjemanTest/venv/lib/python3.8/site-packages/xgboost/data.py\u001B[0m in \u001B[0;36m_transform_np_array\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    134\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 136\u001B[0;31m         raise ValueError('Expecting 2 dimensional numpy.ndarray, got: ',\n\u001B[0m\u001B[1;32m    137\u001B[0m                          data.shape)\n\u001B[1;32m    138\u001B[0m     \u001B[0;31m# flatten the array by rows and ensure it is float32.  we try to avoid\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: ('Expecting 2 dimensional numpy.ndarray, got: ', (188,))"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import xgboost as xgb\n",
    "\n",
    "with open('pss.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "password = lines[0]\n",
    "db = lines[1]\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=password,\n",
    "    database=db,\n",
    "    use_pure=True\n",
    ")\n",
    "\n",
    "my_cursor = mydb.cursor()\n",
    "steps_title_list = []\n",
    "d_steps_title = {}\n",
    "university_name_list = []\n",
    "d_uni_name = {}\n",
    "\n",
    "# def convert_nans(df):\n",
    "#     # job_applicant_id,gender,age,marriage_status,language,degree,skill,num_prev_company,work_interval,steps_title\n",
    "#     df['steps_title'] = df['steps_title'].fillna(6)\n",
    "#     df['age'] = df['age'].fillna(-1)\n",
    "#     df['skill'] = df['skill'].fillna(-1)\n",
    "#     df['marriage_status'] = df['marriage_status'].fillna(-1)\n",
    "#     # df['language'] = df['language'].fillna(-1)\n",
    "#     # df['job_contract_type'] = df['job_contract_type'].fillna(-1)\n",
    "#     df['gender'] = df['gender'].fillna(-1)\n",
    "#     df['degree'] = df['degree'].fillna(-1)\n",
    "#     df['skill'] = df['skill'].fillna(-1)\n",
    "#     df['num_prev_company'] = df['num_prev_company'].fillna(-1)\n",
    "#     df['work_interval'] = df['work_interval'].fillna(-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "my_cursor.execute('select distinct steps_title from useful_data')\n",
    "for item in my_cursor:\n",
    "    steps_title_list.append(item)\n",
    "\n",
    "\n",
    "for title in steps_title_list:\n",
    "    if title[0] == 'نیازمند تعیین وضعیت':\n",
    "        d_steps_title[title[0]] = 0\n",
    "    elif title[0] == 'تایید برای مصاحبه':\n",
    "        d_steps_title[title[0]] = 1\n",
    "    elif title[0] == 'استخدام شده':\n",
    "        d_steps_title[title[0]] = 2\n",
    "    elif title[0] == 'رد شده':\n",
    "        d_steps_title[title[0]] = 3\n",
    "    elif title[0] == 'انصراف از مصاحبه':\n",
    "        d_steps_title[title[0]] = 4\n",
    "    else:\n",
    "        d_steps_title[title[0]] = 6\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_train['steps_title'] = df_train['steps_title'].map(d_steps_title)\n",
    "df_test['steps_title'] = df_test['steps_title'].map(d_steps_title)\n",
    "# convert_nans(df_train)\n",
    "# convert_nans(df_test)\n",
    "x_train =df_train[df_train.columns[[2 , 4 , 5 , 6 , 7 ,10]]]\n",
    "x_test = df_test[df_test.columns[[2 , 4 , 5 , 6 , 7 ,10]]]\n",
    "y_test = df_test['steps_title']\n",
    "y_train = df_train['steps_title']\n",
    "clf_xgb = xgb.XGBClassifier(seed=42)\n",
    "clf_xgb.fit(x_train , y_train , verbose=True, eval_set =[(x_test, y_test)])\n",
    "y_pred=cross_val_predict(clf_xgb,x_test,y_test,cv=10)\n",
    "\n",
    "# y_pred=cross_val_predict(clf,x_test,y_test,cv=10)\n",
    "plot_confusion_matrix(clf_xgb ,x_test , y_test)\n",
    "\n",
    "# print(\"accuracy : \", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}